---
title: 'Structure from Silence: Learning Scene Structure from Ambient Sound'
section: Contributed Papers
openreview: ht3aHpc1hUt
website: https://ificl.github.io/structure-from-silence/
abstract: From whirling ceiling fans to ticking clocks, the sounds that we hear subtly
  vary as we move through a scene. We ask whether these ambient sounds convey information
  about 3D scene structure and, if so, whether they provide a useful learning signal
  for multimodal models. To study this, we collect a dataset of paired audio and RGB-D
  recordings from a variety of quiet indoor scenes. We then train models that estimate
  the distance to nearby walls, given only audio as input. We also use these recordings
  to learn multimodal representations through self-supervision, by training a network
  to associate images with their corresponding sounds. These results suggest that
  ambient sound conveys a surprising amount of information about scene structure,
  and that it is a useful signal for learning multimodal features.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen22b
month: 0
tex_title: 'Structure from Silence: Learning Scene Structure from Ambient Sound'
firstpage: 760
lastpage: 772
page: 760-772
order: 760
cycles: false
bibtex_author: Chen, Ziyang and Hu, Xixi and Owens, Andrew
author:
- given: Ziyang
  family: Chen
- given: Xixi
  family: Hu
- given: Andrew
  family: Owens
date: 2022-01-11
address:
container-title: Proceedings of the 5th Conference on Robot Learning
volume: '164'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 1
  - 11
pdf: https://proceedings.mlr.press/v164/chen22b/chen22b.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v164/chen22b/chen22b-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
