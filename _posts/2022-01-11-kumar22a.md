---
title: A Workflow for Offline Model-Free Robotic Reinforcement Learning
section: Contributed Papers
openreview: fy4ZBWxYbIo
website: https://sites.google.com/corp/view/offline-rl-workflow
abstract: 'Offline reinforcement learning (RL) enables learning control policies by
  utilizing only prior experience, without any online interaction. This can allow
  robots to acquire generalizable skills from large and diverse datasets, without
  any costly or unsafe online data collection. Despite recent algorithmic advances
  in offline RL, applying these methods to real-world problems has proven challenging.
  Although offline RL methods can learn from prior data, there is no clear and well-understood
  process for making various design choices, from model ar- architecture to algorithm
  hyperparameters, without actually evaluating the learned policies online. In this
  paper, our aim is to develop a practical workflow for using offline RL analogous
  to the relatively well-understood workflows for supervised learning problems. To
  this end, we devise a set of metrics and conditions that can be tracked over the
  course of offline training and can inform the practitioner about how the algorithm
  and model architecture should be adjusted to improve final performance. Our workflow
  is derived from a conceptual understanding of the behavior of conservative offline
  RL algorithms and cross-validation in supervised learning. We demonstrate the efficacy
  of this workflow in producing effective policies without any online tuning, both
  in several simulated robotic learning scenarios and for three tasks on two distinct
  real robots, focusing on learning manipulation skills with raw image observations
  with sparse binary rewards. Explanatory video and additional content can be found
  at https://sites.google.com/view/offline-rl-workflow. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kumar22a
month: 0
tex_title: A Workflow for Offline Model-Free Robotic Reinforcement Learning
firstpage: 417
lastpage: 428
page: 417-428
order: 417
cycles: false
bibtex_author: Kumar, Aviral and Singh, Anikait and Tian, Stephen and Finn, Chelsea
  and Levine, Sergey
author:
- given: Aviral
  family: Kumar
- given: Anikait
  family: Singh
- given: Stephen
  family: Tian
- given: Chelsea
  family: Finn
- given: Sergey
  family: Levine
date: 2022-01-11
address:
container-title: Proceedings of The 5th Conference on Robot Learning
volume: '164'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 1
  - 11
pdf: https://proceedings.mlr.press/v164/kumar22a/kumar22a.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v164/kumar22a/kumar22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
