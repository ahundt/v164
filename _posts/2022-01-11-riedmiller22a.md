---
title: Collect & Infer - a fresh look at data-efficient Reinforcement Learning
section: Blue Sky Papers
openreview: qscEfLT5VJK
abstract: 'This position paper proposes a fresh look at Reinforcement Learning (RL)
  from the perspective of data-efficiency. RL has gone through three major stages:
  pure on-line RL where every data-point is considered only once, RL with a replay
  buffer where additional learning is done on a portion of the experience, and finally
  transition memory based RL, where, conceptually, all transitions are stored,  and
  flexibly re-used in every update step. While inferring knowledge from all stored
  experience has led to a tremendous gain in data-efficiency, the question of how
  this data is collected has been vastly understudied. We argue that data-efficiency
  can only be achieved through careful consideration of both aspects. We propose to
  make this insight explicit via a paradigm that we call ’Collect and Infer’, which
  explicitly models RL as two separate but interconnected processes, concerned with
  data collection and knowledge inference respectively. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: riedmiller22a
month: 0
tex_title: Collect & Infer - a fresh look at data-efficient Reinforcement Learning
firstpage: 1736
lastpage: 1744
page: 1736-1744
order: 1736
cycles: false
bibtex_author: Riedmiller, Martin and Springenberg, Jost Tobias and Hafner, Roland
  and Heess, Nicolas
author:
- given: Martin
  family: Riedmiller
- given: Jost Tobias
  family: Springenberg
- given: Roland
  family: Hafner
- given: Nicolas
  family: Heess
date: 2022-01-11
address:
container-title: Proceedings of the 5th Conference on Robot Learning
volume: '164'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 1
  - 11
pdf: https://proceedings.mlr.press/v164/riedmiller22a/riedmiller22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
