---
title: Language Grounding with 3D Objects
section: Contributed Papers
openreview: U1GhcnR4jNI
software: https://github.com/snaredataset/snare
abstract: Seemingly simple natural language requests to a robot are generally underspecified,
  for example "Can you bring me the wireless mouse?" Flat images of candidate mice
  may not provide the discriminative information needed for "wireless." The world,
  and objects in it, are not flat images but complex 3D shapes. If a human requests
  an object based on any of its basic properties, such as color, shape, or texture,
  robots should perform the necessary exploration to accomplish the task. In particular,
  while substantial effort and progress has been made on understanding explicitly
  visual attributes like color and category, comparatively little progress has been
  made on understanding language about shapes and contours. In this work, we introduce
  a novel reasoning task that targets both visual and non-visual language about 3D
  objects. Our new benchmark ShapeNet Annotated with Referring Expressions (SNARE)
  requires a model to choose which of two objects is being referenced by a natural
  language description. We introduce several CLIP-based models for distinguishing
  objects and demonstrate that while recent advances in jointly modeling vision and
  language are useful for robotic language understanding, it is still the case that
  these image-based models are weaker at understanding the 3D nature of objects â€“
  properties which play a key role in manipulation. We find that adding view estimation
  to language grounding models improves accuracy on both SNARE and when identifying
  objects referred to in language on a robot platform, but note that a large gap remains
  between these models and human performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: thomason22a
month: 0
tex_title: Language Grounding with 3D Objects
firstpage: 1691
lastpage: 1701
page: 1691-1701
order: 1691
cycles: false
bibtex_author: Thomason, Jesse and Shridhar, Mohit and Bisk, Yonatan and Paxton, Chris
  and Zettlemoyer, Luke
author:
- given: Jesse
  family: Thomason
- given: Mohit
  family: Shridhar
- given: Yonatan
  family: Bisk
- given: Chris
  family: Paxton
- given: Luke
  family: Zettlemoyer
date: 2022-01-11
address:
container-title: Proceedings of The 5th Conference on Robot Learning
volume: '164'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 1
  - 11
pdf: https://proceedings.mlr.press/v164/thomason22a/thomason22a.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v164/thomason22a/thomason22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
