---
title: Learning Reward Functions from Scale Feedback
section: Contributed Papers
openreview: udFuJTvlhsJ
website: https://sites.google.com/corp/view/reward-learning-scale-feedback
abstract: Today’s robots are increasingly interacting with people and need to efficiently
  learn inexperienced user’s preferences. A common framework is to iteratively query
  the user about which of two presented robot trajectories they prefer. While this
  minimizes the users effort, a strict choice does not yield any information on how
  much one trajectory is preferred. We propose scale feedback, where the user utilizes
  a slider to give more nuanced information. We introduce a probabilistic model on
  how users would provide feedback and derive a learning framework for the robot.
  We demonstrate the performance benefit of slider feedback in simulations, and validate
  our approach in two user studies suggesting that scale feedback enables more effective
  learning in practice.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wilde22a
month: 0
tex_title: Learning Reward Functions from Scale Feedback
firstpage: 353
lastpage: 362
page: 353-362
order: 353
cycles: false
bibtex_author: Wilde, Nils and Biyik, Erdem and Sadigh, Dorsa and Smith, Stephen L.
author:
- given: Nils
  family: Wilde
- given: Erdem
  family: Biyik
- given: Dorsa
  family: Sadigh
- given: Stephen L.
  family: Smith
date: 2022-01-11
address:
container-title: Proceedings of The 5th Conference on Robot Learning
volume: '164'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 1
  - 11
pdf: https://proceedings.mlr.press/v164/wilde22a/wilde22a.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v164/wilde22a/wilde22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
